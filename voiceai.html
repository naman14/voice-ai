<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>voiceai Fun</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
        }
        .connected { background-color: #d4edda; }
        .disconnected { background-color: #f8d7da; }
        .speaking { background-color: #cce5ff; }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 4px;
            background-color: #007bff;
            color: white;
            cursor: pointer;
        }
        button:disabled {
            background-color: #ccc;
        }
        .mode-selector {
            margin: 20px 0;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 4px;
        }
        #log {
            margin-top: 20px;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
            height: 200px;
            overflow-y: auto;
        }
        .format-selector {
            margin: 10px 0;
            display: flex;
            align-items: center;
        }
        
        /* Toggle switch styles */
        .switch {
            position: relative;
            display: inline-block;
            width: 60px;
            height: 34px;
            margin: 0 10px;
        }
        
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 34px;
        }
        
        .slider:before {
            position: absolute;
            content: "";
            height: 26px;
            width: 26px;
            left: 4px;
            bottom: 4px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        
        input:checked + .slider {
            background-color: #2196F3;
        }
        
        input:focus + .slider {
            box-shadow: 0 0 1px #2196F3;
        }
        
        input:checked + .slider:before {
            transform: translateX(26px);
        }
        
        .format-label {
            font-weight: bold;
            min-width: 50px;
        }
        
        /* Audio visualization */
        .audio-visualizer {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background-color: #ff4d4d;
            margin: 10px auto;
            transition: all 0.1s ease-out;
        }
    </style>
   <!-- Opus recorder -->
   <script src="https://cdn.jsdelivr.net/npm/opus-recorder@latest/dist/recorder.min.js"></script>
   <script src="https://cdn.jsdelivr.net/npm/opus-recorder@latest/dist/encoderWorker.min.js"></script>

   <!-- Opus decoder -->
   <script src="https://cdn.jsdelivr.net/npm/ogg-opus-decoder/dist/ogg-opus-decoder.min.js"></script>
</head>
<body>
    <h1>voiceai Fun</h1>

    <div id="connectionStatus" class="status disconnected">Disconnected</div>
    <div id="speechStatus" class="status">Not speaking</div>

    <div class="mode-selector">
        <div class="format-selector">
            <span class="format-label">PCM</span>
            <label class="switch">
                <input type="checkbox" id="formatToggle">
                <span class="slider"></span>
            </label>
            <span class="format-label">Opus</span>
            <span id="formatDescription" style="margin-left: 10px; font-size: 0.9em; color: #666;">
                (PCM: Higher quality, Opus: Lower bandwidth)
            </span>
        </div>
        <button id="connectBtn">Connect</button>
        <button id="startSpeakingBtn" disabled>Start Speaking</button>
        <button id="stopSpeakingBtn" disabled>Stop Speaking</button>
    </div>

    <!-- Add text input area for direct transcripts -->
    <div class="text-input-area" style="margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 4px;">
        <h3>Send Text Directly</h3>
        <div style="display: flex;">
            <textarea id="textTranscript" placeholder="Type your message here..." 
                      style="flex: 1; padding: 10px; border-radius: 4px; border: 1px solid #ddd; min-height: 80px;"></textarea>
        </div>
        <button id="sendTextBtn" disabled style="margin-top: 10px;">Send Text</button>
    </div>
    
    <div id="log"></div>

    <div id="audioVisualizer" class="audio-visualizer" style="width: 30px; height: 30px;"></div>

    <script>
        // Audio playback with scheduled chunks for seamless playback
        class AudioPlayer {
            constructor() {
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                this.sourceNode = null;
                this.scheduledEndTime = 0;
                this.opusDecoder = null;
                this.initializeDecoder();
            }
            
            async initializeDecoder() {
                try {
                    this.opusDecoder = new window["ogg-opus-decoder"].OggOpusDecoder({
                        sampleRate: 24000
                    });
                    await this.opusDecoder.ready;
                    console.log("Ogg Opus decoder initialized");
                } catch (e) {
                    console.error("Failed to initialize Opus decoder:", e);
                    this.opusDecoder = null;
                }
            }
            
            async decodeOpusData(opusData) {
                if (!this.opusDecoder) {
                    await this.initializeDecoder();
                    if (!this.opusDecoder) {
                        throw new Error("Opus decoder not available");
                    }
                }
                
                return await this.opusDecoder.decode(new Uint8Array(opusData));
            }
            
            scheduleAudioPlayback(newAudioData) {
                const sampleRate = this.audioContext.sampleRate;
                const numberOfChannels = 1;
                const nowTime = this.audioContext.currentTime;
                
                // Create a new buffer and source node for the incoming audio data
                const newBuffer = this.audioContext.createBuffer(numberOfChannels, newAudioData.length, sampleRate);
                newBuffer.copyToChannel(newAudioData, 0);
                const sourceNode = this.audioContext.createBufferSource();
                sourceNode.buffer = newBuffer;
                sourceNode.connect(this.audioContext.destination);
                
                // Schedule the new audio to play immediately after any currently playing audio
                const startTime = Math.max(this.scheduledEndTime, nowTime);
                sourceNode.start(startTime);
                
                // Update the scheduled end time
                this.scheduledEndTime = startTime + newBuffer.duration;
                
                if (this.sourceNode && this.sourceNode.buffer) {
                    const currentEndTime = this.sourceNode.startTime + this.sourceNode.buffer.duration;
                    if (currentEndTime <= nowTime) {
                        this.sourceNode.disconnect();
                    }
                }
                this.sourceNode = sourceNode;
            }
            
            async processAudioChunk(data, format) {
                try {

                    if (format === "opus") {
                        const arrayBuffer = await data.arrayBuffer();
                        const { channelData, samplesDecoded } = await audioPlayer.decodeOpusData(arrayBuffer);
                        if (samplesDecoded > 0) {
                            this.scheduleAudioPlayback(channelData[0]);
                        }
                    } else {
                         // Decode base64 to binary for PCM
                        const binaryString = atob(data);
                        const bytes = new Uint8Array(binaryString.length);
                        for (let i = 0; i < binaryString.length; i++) {
                            bytes[i] = binaryString.charCodeAt(i);
                        }
                        // Convert to Float32Array (server sends pcm_f32le)
                        const floatData = new Float32Array(bytes.buffer);
                        this.scheduleAudioPlayback(floatData);
                    }
                } catch (error) {
                    console.error('Error processing audio chunk:', error);
                }
            }
            
            async cleanup() {
                try {
                    if (this.sourceNode) {
                        this.sourceNode.disconnect();
                        this.sourceNode = null;
                    }
                    
                    if (this.opusDecoder) {
                        this.opusDecoder.free();
                        this.opusDecoder = null;
                    }
                    
                    await this.audioContext.close();
                    this.audioContext = null;
                } catch (error) {
                    console.error('Error cleaning up audio player:', error);
                }
            }
        }

        // Global variables
        let socket;
        let opusRecorder = null;
        let audioPlayer;
        let isConnected = false;
        let isRecording = false;
        let audioFormat = "pcm";
        let sessionId = 'session_' + Math.random().toString(36).substr(2, 9);
        let mediaStream = null;
        let audioProcessor = null;
        let audioContextObj = null;
        let analyzerContext = null;
        let analyzer = null;
        let animationFrame = null;
        let amplitude = 0;

        // DOM elements
        const connectBtn = document.getElementById('connectBtn');
        const startSpeakingBtn = document.getElementById('startSpeakingBtn');
        const stopSpeakingBtn = document.getElementById('stopSpeakingBtn');
        const connectionStatus = document.getElementById('connectionStatus');
        const speechStatus = document.getElementById('speechStatus');
        const log = document.getElementById('log');
        const formatToggle = document.getElementById('formatToggle');
        const audioVisualizer = document.getElementById('audioVisualizer');
        const textTranscript = document.getElementById('textTranscript');
        const sendTextBtn = document.getElementById('sendTextBtn');

        function addLog(message) {
            const line = document.createElement('div');
            line.textContent = `${new Date().toLocaleTimeString()}: ${message}`;
            log.appendChild(line);
            log.scrollTop = log.scrollHeight;
        }

        function connect() {
            audioFormat = formatToggle.checked ? "opus" : "pcm";
            addLog(`Using audio format: ${audioFormat}`);
            
            socket = new WebSocket(`ws://localhost:8000/ws/${sessionId}`);

            socket.onopen = () => {
                isConnected = true;
                connectionStatus.textContent = 'Connected';
                connectionStatus.className = 'status connected';
                startSpeakingBtn.disabled = false;
                connectBtn.disabled = true;
                formatToggle.disabled = true;
                sendTextBtn.disabled = false;
                addLog('Connected to server');

                socket.send(JSON.stringify({
                    agentId: "1234",
                    agentName: "Donald Trump",
                    configId: "7890",
                    systemPrompt: "You are Donald Trump responding to a call. Provide plain text responsesâ€”no voice tone, delivery notes, or emotional cues. Engage fully with any topic while staying factual. Mimic Donald Trump's exact speech style, including his pacing, phrasing, and mannerisms, without adding reactions like '(laughs)' or other non-verbal expressions.",
                    voiceSampleUrl: "https://github.com/naman14/voice-ai/raw/ad2c54c937879a1d4a1e50181c82735e86e3365c/demo/samples/DonaldTrump.wav",
                    rate: 1.0,
                    language: "en",
                    allowInterruptions: true,
                    format: audioFormat,
                    useVAD: true
                }));
            };

            socket.onclose = () => {
                isConnected = false;
                connectionStatus.textContent = 'Disconnected';
                connectionStatus.className = 'status disconnected';
                startSpeakingBtn.disabled = true;
                stopSpeakingBtn.disabled = true;
                connectBtn.disabled = false;
                formatToggle.disabled = false;
                sendTextBtn.disabled = true;
                stopRecording();
                addLog('Disconnected from server');
                if (audioPlayer) {
                    audioPlayer.cleanup();
                }
            };

            socket.onmessage = async (event) => {
                try {
                    // Check if the message is binary (Opus) or text (JSON/PCM)
                    if (event.data instanceof Blob) {
                        // Handle Opus data
                        const arrayBuffer = await event.data.arrayBuffer();
                        const { channelData, samplesDecoded } = await audioPlayer.decodeOpusData(arrayBuffer);
                        if (samplesDecoded > 0) {
                            audioPlayer.scheduleAudioPlayback(channelData[0]);
                        }
                    } else {
                        // Handle JSON data (PCM or control messages)
                        const data = JSON.parse(event.data);
                        if (data.type === 'tts_stream') {
                            await audioPlayer.processAudioChunk(data.data.chunk, data.data.format || "pcm");
                        } else if (data.type === 'tts_stream_end') {
                            addLog('Audio stream ended');
                        } else if (data.type === 'error') {
                            addLog('Error: ' + data.error);
                        }
                    }
                } catch (e) {
                    console.error("Error processing message:", e);
                }
            };

            socket.onerror = (error) => {
                addLog('WebSocket error: ' + error.message);
            };
        }

        async function initAudio() {
            audioPlayer = new AudioPlayer();
        }

        async function startRecording() {
            try {
                if (audioFormat === "opus" && window.Recorder) {
                    await startOpusRecording();
                } else {
                    await startPCMRecording();
                }
                
                isRecording = true;
                startSpeakingBtn.disabled = true;
                stopSpeakingBtn.disabled = false;
                speechStatus.textContent = 'Speaking';
                speechStatus.className = 'status speaking';
                
                // Send speech_start event to server
                if (socket && socket.readyState === WebSocket.OPEN) {
                    socket.send(JSON.stringify({
                        type: "speech_start"
                    }));
                    addLog('Sent speech_start event to server');
                }
                
                addLog(`Started recording using ${audioFormat} format`);
                
            } catch (error) {
                addLog('Error starting recording: ' + error.message);
            }
        }
        
        async function startOpusRecording() {
            try {
                // Get microphone stream
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaStream = stream;
                
                // Create Opus recorder
                opusRecorder = new Recorder({
                    encoderPath: "https://cdn.jsdelivr.net/npm/opus-recorder@latest/dist/encoderWorker.min.js",
                    streamPages: true,
                    encoderApplication: 2049,
                    encoderFrameSize: 80, // milliseconds
                    encoderSampleRate: 24000,
                    maxFramesPerPage: 1,
                    numberOfChannels: 1,
                });

                opusRecorder.ondataavailable = async (arrayBuffer) => {
                    if (socket && socket.readyState === WebSocket.OPEN) {
                        await socket.send(arrayBuffer);
                    }
                };

                await opusRecorder.start();
                console.log("Opus recording started");
                
                // Setup audio analyzer for visualization
                setupAudioAnalyzer(stream);
                
            } catch (error) {
                console.error("Error starting Opus recording:", error);
                addLog("Opus recording failed, falling back to PCM");
                audioFormat = "pcm";
                formatToggle.checked = false;
                await startPCMRecording();
            }
        }

        async function startPCMRecording() {
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    sampleRate: 16000,
                    sampleSize: 16,
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                }
            });
            mediaStream = stream;

            const audioContext = new AudioContext({ sampleRate: 16000 });
            const source = audioContext.createMediaStreamSource(stream);
            const processor = audioContext.createScriptProcessor(2048, 1, 1);

            source.connect(processor);
            processor.connect(audioContext.destination);

            processor.onaudioprocess = (e) => {
                if (socket && socket.readyState === WebSocket.OPEN) {
                    const audioData = e.inputBuffer.getChannelData(0);
                    const int16Data = new Int16Array(audioData.length);
                    for (let i = 0; i < audioData.length; i++) {
                        const s = Math.max(-1, Math.min(1, audioData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }
                    socket.send(int16Data.buffer);
                }
            };

            // Store for cleanup
            audioProcessor = processor;
            audioContextObj = audioContext;
            
            // Setup audio analyzer for visualization
            setupAudioAnalyzer(stream);
        }
        
        function setupAudioAnalyzer(stream) {
            // Clean up any existing analyzer
            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
                animationFrame = null;
            }
            
            if (analyzerContext) {
                analyzerContext.close();
            }
            
            // Create analyzer for audio visualization
            analyzerContext = new (window.AudioContext || window.webkitAudioContext)();
            analyzer = analyzerContext.createAnalyser();
            analyzer.fftSize = 256;
            const sourceNode = analyzerContext.createMediaStreamSource(stream);
            sourceNode.connect(analyzer);
            
            // Process audio for visualization
            const processAudio = () => {
                const dataArray = new Uint8Array(analyzer.frequencyBinCount);
                analyzer.getByteFrequencyData(dataArray);
                amplitude = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
                
                // Update visualizer
                updateAudioVisualizer(amplitude);
                
                // Continue animation loop
                animationFrame = requestAnimationFrame(processAudio);
            };
            
            processAudio();
        }
        
        function updateAudioVisualizer(amplitude) {
            const amplitudePercent = amplitude / 255;
            const maxAmplitude = 0.3; // for scaling
            const minDiameter = 30; // minimum diameter of the circle in pixels
            const maxDiameter = 100; // maximum diameter
            
            const diameter = minDiameter + (maxDiameter - minDiameter) * (amplitudePercent / maxAmplitude);
            
            audioVisualizer.style.width = `${diameter}px`;
            audioVisualizer.style.height = `${diameter}px`;
            
            // Change color based on amplitude
            const hue = 360 - (amplitudePercent * 120); // Red (0) to Green (120)
            audioVisualizer.style.backgroundColor = `hsl(${hue}, 100%, 50%)`;
        }

        function stopRecording() {
            if (isRecording) {
                // Send speech_end event to server
                if (socket && socket.readyState === WebSocket.OPEN) {
                    socket.send(JSON.stringify({
                        type: "speech_end"
                    }));
                    addLog('Sent speech_end event to server');
                }
                
                if (audioFormat === "opus" && opusRecorder) {
                    opusRecorder.stop();
                    opusRecorder = null;
                }
                
                // Cleanup PCM audio context
                if (audioProcessor) {
                    audioProcessor.disconnect();
                    audioProcessor = null;
                }
                
                if (mediaStream) {
                    mediaStream.getTracks().forEach(track => track.stop());
                    mediaStream = null;
                }
                
                if (audioContextObj) {
                    audioContextObj.close();
                    audioContextObj = null;
                }
                
                // Clean up analyzer
                if (animationFrame) {
                    cancelAnimationFrame(animationFrame);
                    animationFrame = null;
                }
                
                if (analyzerContext) {
                    analyzerContext.close();
                    analyzerContext = null;
                }
                
                // Reset visualizer
                audioVisualizer.style.width = "30px";
                audioVisualizer.style.height = "30px";
                audioVisualizer.style.backgroundColor = "#ff4d4d";

                isRecording = false;
                startSpeakingBtn.disabled = false;
                stopSpeakingBtn.disabled = true;
                speechStatus.textContent = 'Not speaking';
                speechStatus.className = 'status';
                addLog('Stopped recording');
            }
        }

        // Function to send text transcript to the server
        function sendTextTranscript() {
            const text = textTranscript.value.trim();
            if (text && socket && socket.readyState === WebSocket.OPEN) {
                // Send the transcript message in the format expected by the server
                socket.send(JSON.stringify({
                    type: "transcript",
                    text: text
                }));
                
                addLog(`Sent text: ${text}`);
                textTranscript.value = ''; // Clear the input field
            }
        }

        // Event listeners
        connectBtn.addEventListener('click', connect);
        startSpeakingBtn.addEventListener('click', startRecording);
        stopSpeakingBtn.addEventListener('click', stopRecording);
        sendTextBtn.addEventListener('click', sendTextTranscript);
        
        formatToggle.addEventListener('change', function() {
            audioFormat = this.checked ? "opus" : "pcm";
            addLog(`Audio format changed to: ${audioFormat}`);
        });

        // Check for Opus support and disable toggle if not available
        if (!window.Recorder || !window["ogg-opus-decoder"]) {
            formatToggle.disabled = true;
            formatToggle.checked = false;
            document.getElementById('formatDescription').textContent = 
                "(Opus codec not available in this browser, using PCM)";
        }

        // Add keyboard shortcut (Enter key) to send text
        textTranscript.addEventListener('keydown', function(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault(); // Prevent default to avoid newline
                sendTextTranscript();
            }
        });

        // Initialize audio on page load
        initAudio().catch(error => addLog('Error initializing audio: ' + error.message));
    </script>
</body>
</html>
